{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cec89d70",
      "metadata": {},
      "source": [
        "## Setup and Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "597a240e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nafi/dev/shared-task/task2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import gc\n",
        "import ast\n",
        "import signal\n",
        "import sys\n",
        "from io import StringIO\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6227b62f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU: NVIDIA GeForce RTX 3090 Ti\n",
            "GPU Memory: 22.0 GB\n"
          ]
        }
      ],
      "source": [
        "# Memory management and system check\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "clear_memory()\n",
        "\n",
        "# System resources\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
        "else:\n",
        "    print(\"No GPU detected - using CPU (will be very slow)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b29bc31",
      "metadata": {},
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c85e415c",
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_data_path = 'PATH_TO_ORIGINAL_DEV_DATASET'\n",
        "dev_df = pd.read_csv(dev_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a202cbd8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\n",
        "        \"text-generation\", \n",
        "        model=\"unsloth/Phi-4-unsloth-bnb-4bit\",\n",
        "        trust_remote_code=True,  # Phi-4 may need trust_remote_code\n",
        "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e6dba27e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_prompt(example):\n",
        "        \"\"\"Format a single example into the required prompt format\"\"\"\n",
        "        instruction = example['instruction']\n",
        "        test_list = example['test_list']\n",
        "        \n",
        "        # Parse function name from instruction\n",
        "        function_name = \"unknown_function\"\n",
        "        if \"Example:\" in instruction:\n",
        "            example_part = instruction.split(\"Example:\")[1].strip()\n",
        "            func_match = re.search(r'(\\w+)\\s*\\(', example_part)\n",
        "            if func_match:\n",
        "                function_name = func_match.group(1)\n",
        "        \n",
        "       \n",
        "        system_message = \"\"\"You are an expert Python programmer. Your task is to generate clean, efficient, and correct Python functions that pass all given test cases.\n",
        "\n",
        "CRITICAL RULES:\n",
        "1. ALWAYS wrap your code in ```python ``` blocks\n",
        "2. Write ONLY the function implementation, no extra explanations\n",
        "3. Use the EXACT function name from the example\n",
        "4. Ensure the function passes ALL test cases\n",
        "5. Handle edge cases and invalid inputs appropriately\n",
        "6. Use appropriate data types based on test case patterns\n",
        "\n",
        "Here are examples of how to solve different types of problems:\n",
        "\n",
        "EXAMPLE 1 - String Processing:\n",
        "Task: একটি প্রদত্ত স্ট্রিং-এ প্রথম পুনরাবৃত্ত অক্ষর খুঁজে পেতে একটি পাইথন ফাংশন লিখুন।\n",
        "Test Cases:\n",
        "assert first_repeated_char(\"abcabc\") == \"a\"\n",
        "assert first_repeated_char(\"abc\") == \"None\"  \n",
        "assert first_repeated_char(\"123123\") == \"1\"\n",
        "\n",
        "Expected Solution:\n",
        "```python\n",
        "def first_repeated_char(s):\n",
        "    seen = set()\n",
        "    for char in s:\n",
        "        if char in seen:\n",
        "            return char\n",
        "        seen.add(char)\n",
        "    return \"None\"\n",
        "```\n",
        "\n",
        "EXAMPLE 2 - Mathematical Function:\n",
        "Task: প্রদত্ত পূর্ণসংখ্যাটি একটি মৌলিক সংখ্যা কিনা তা পরীক্ষা করার জন্য একটি ফাংশন লিখুন।\n",
        "Test Cases:\n",
        "assert prime_num(13) == True\n",
        "assert prime_num(7) == True\n",
        "assert prime_num(-1010) == False\n",
        "\n",
        "Expected Solution:\n",
        "```python\n",
        "def prime_num(n):\n",
        "    if n < 2:\n",
        "        return False\n",
        "    if n == 2:\n",
        "        return True\n",
        "    if n % 2 == 0:\n",
        "        return False\n",
        "    for i in range(3, int(n**0.5) + 1, 2):\n",
        "        if n % i == 0:\n",
        "            return False\n",
        "    return True\n",
        "```\n",
        "\n",
        "\n",
        "Code Quality Standards:\n",
        "- Write code with proper indentation\n",
        "- Optimize for correctness first, then efficiency\n",
        "- Handle common edge cases (empty inputs, None values, negative numbers, etc.)\n",
        "- Return the exact data type shown in test cases\"\"\"\n",
        "        \n",
        "        user_prompt = f\"\"\"Generate a Python function for this problem:\n",
        "\n",
        "**Task**: {instruction}\n",
        "\n",
        "**Test Cases**:\n",
        "{test_list}\n",
        "\n",
        "**Expected Function Name**: {function_name}\n",
        "\n",
        "Requirements:\n",
        "- Follow the examples shown in the system message\n",
        "- Analyze the test cases carefully to understand input/output patterns\n",
        "- Implement the function to pass ALL test cases exactly\n",
        "- Return the appropriate data type as shown in test cases\n",
        "- Handle edge cases gracefully (empty inputs, invalid values, etc.)\n",
        "- Use efficient algorithms where applicable\n",
        "\n",
        "Generate ONLY the Python function wrapped in ```python ``` blocks. No explanations needed.\"\"\"\n",
        "        \n",
        "        # Format for Phi-4 using chat template\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": f\"System: {system_message}\\n\\nUser: {user_prompt}\"}\n",
        "        ]\n",
        "        \n",
        "        # Try to apply chat template, fallback to manual format if needed\n",
        "        try:\n",
        "            formatted_prompt = pipe.tokenizer.apply_chat_template(\n",
        "                messages, \n",
        "                tokenize=False, \n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  Chat template failed, using manual format: {e}\")\n",
        "            # Fallback to Phi-4 manual format\n",
        "            formatted_prompt = f\"\"\"<|im_start|>user<|im_sep|>{system_message}\n",
        "\n",
        "{user_prompt}<|im_end|>\n",
        "<|im_start|>assistant<|im_sep|>\"\"\"\n",
        "        \n",
        "        return formatted_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7da2bd26",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preparing data: 100%|██████████| 400/400 [00:00<00:00, 56222.03row/s]\n",
            "Formatting prompts: 100%|██████████| 400/400 [00:00<00:00, 47588.19prompt/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Formatted 400 prompts\n",
            "Creating dataset from formatted prompts...\n",
            "Dataset created with 400 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "instructions_data = []\n",
        "formatted_prompts = []\n",
        "ids_list = []\n",
        "for _, row in tqdm(dev_df.iterrows(), desc=\"Preparing data\", unit=\"row\", total=len(dev_df)):\n",
        "    instructions_data.append({\n",
        "        'instruction': row['instruction'],\n",
        "        'test_list': row['test_list'],\n",
        "        'id': row['id']\n",
        "    })\n",
        "\n",
        "for item in tqdm(instructions_data, desc=\"Formatting prompts\", unit=\"prompt\"):\n",
        "    formatted_prompt = format_prompt(item)\n",
        "    formatted_prompts.append(formatted_prompt)\n",
        "    ids_list.append(item['id'])\n",
        "\n",
        "print(f\"Formatted {len(formatted_prompts)} prompts\")\n",
        "print(\"Creating dataset from formatted prompts...\")\n",
        "\n",
        "dataset_dict = {\n",
        "    'prompt': formatted_prompts,\n",
        "    'id': ids_list\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(dataset_dict)\n",
        "print(f\"Dataset created with {len(dataset)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dbb36729",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_function_name_from_test(test_cases_str):\n",
        "    \"\"\"Extract function name from test cases for better error reporting\"\"\"\n",
        "    try:\n",
        "        inner_str = ast.literal_eval(test_cases_str)\n",
        "        test_cases = ast.literal_eval(inner_str)\n",
        "        if test_cases:\n",
        "            # Find function name in first test case\n",
        "            func_match = re.search(r'assert\\s+(\\w+)\\s*\\(', test_cases[0])\n",
        "            if func_match:\n",
        "                return func_match.group(1)\n",
        "    except:\n",
        "        pass\n",
        "    return \"function\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94c3866c",
      "metadata": {},
      "source": [
        "## Simple Code Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ff619e20",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_code(prompt):\n",
        "    \"\"\"\n",
        "    Generate code from the given prompt using the language model pipeline.\n",
        "    Returns: (generated_code)\n",
        "    \"\"\"\n",
        "    \n",
        "    result = pipe(\n",
        "                prompt,\n",
        "                max_new_tokens=1024,\n",
        "                temperature=0.1,\n",
        "                top_p=0.95,\n",
        "                do_sample=True,\n",
        "                return_full_text=False,\n",
        "                pad_token_id=pipe.tokenizer.eos_token_id if hasattr(pipe.tokenizer, 'eos_token_id') else None\n",
        "            )\n",
        "            \n",
        "    generated_code = result[0]['generated_text'].strip()\n",
        "    \n",
        "    return generated_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6db98b74",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:   2%|▎         | 10/400 [00:31<22:23,  3.45s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Phi-4 code generation:   5%|▌         | 20/400 [00:51<15:22,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 20 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  10%|█         | 40/400 [01:28<11:25,  1.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 40 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  12%|█▎        | 50/400 [01:49<11:34,  1.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Progress Update after 50 samples:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  15%|█▌        | 60/400 [02:10<11:17,  1.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 60 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  20%|██        | 80/400 [02:49<09:55,  1.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 80 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  25%|██▌       | 100/400 [03:38<15:01,  3.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 100 samples\n",
            "\n",
            "Progress Update after 100 samples:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  30%|███       | 120/400 [04:22<07:49,  1.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 120 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  35%|███▌      | 140/400 [05:05<09:00,  2.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 140 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  38%|███▊      | 150/400 [05:28<09:03,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Progress Update after 150 samples:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  40%|████      | 160/400 [05:53<10:45,  2.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 160 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  45%|████▌     | 180/400 [06:45<10:14,  2.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 180 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  50%|█████     | 200/400 [07:29<05:21,  1.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 200 samples\n",
            "\n",
            "Progress Update after 200 samples:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  55%|█████▌    | 220/400 [08:08<06:31,  2.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 220 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  60%|██████    | 240/400 [09:13<10:48,  4.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 240 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  62%|██████▎   | 250/400 [09:41<05:14,  2.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Progress Update after 250 samples:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  65%|██████▌   | 260/400 [10:10<05:53,  2.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 260 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  70%|███████   | 280/400 [10:58<05:20,  2.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 280 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  75%|███████▌  | 300/400 [11:38<03:23,  2.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 300 samples\n",
            "\n",
            "Progress Update after 300 samples:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  80%|████████  | 320/400 [12:30<03:31,  2.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 320 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  85%|████████▌ | 340/400 [13:25<02:12,  2.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 340 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  88%|████████▊ | 350/400 [13:48<02:18,  2.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Progress Update after 350 samples:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  90%|█████████ | 360/400 [14:11<01:25,  2.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 360 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation:  95%|█████████▌| 380/400 [14:55<00:53,  2.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 380 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Phi-4 code generation: 100%|██████████| 400/400 [15:47<00:00,  2.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Memory cleared after 400 samples\n",
            "\n",
            "Progress Update after 400 samples:\n",
            "PHI-4 CODE GENERATION COMPLETED!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "responses = []\n",
        "\n",
        "for idx in tqdm(range(len(dataset)), desc=\"Phi-4 code generation\"):\n",
        "    try:\n",
        "        # Get sample data\n",
        "        prompt = dataset[idx]['prompt']\n",
        "        sample_id = dataset[idx]['id']\n",
        "        \n",
        "        # Get corresponding test cases and instruction from original data\n",
        "        original_row = dev_df[dev_df['id'] == sample_id].iloc[0]\n",
        "        test_cases_str = original_row['test_list']\n",
        "        instruction = original_row['instruction']\n",
        "        \n",
        "        # Generate code\n",
        "        generated_code = generate_code(prompt)\n",
        "        \n",
        "        responses.append(generated_code)   \n",
        "        \n",
        "        # Memory management - clear every 20 samples\n",
        "        if (idx + 1) % 20 == 0:\n",
        "            clear_memory()\n",
        "            print(f\"\\nMemory cleared after {idx + 1} samples\")\n",
        "            \n",
        "        # Progress update every 50 samples\n",
        "        if (idx + 1) % 50 == 0:\n",
        "            print(f\"\\nProgress Update after {idx + 1} samples:\") \n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Complete failure for ID {sample_id}: {e}\")\n",
        "        responses.append(\"def placeholder(): pass\")\n",
        "        continue\n",
        "\n",
        "print(\"PHI-4 CODE GENERATION COMPLETED!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0fc27121",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUBMISSION SAVED!\n",
            "File: submission.json\n",
            "Total samples: 400\n"
          ]
        }
      ],
      "source": [
        "submission_data = []\n",
        "for i, (_, row) in enumerate(dev_df.iterrows()):\n",
        "    submission_data.append({\n",
        "        \"id\": int(row['id']),\n",
        "        \"response\": responses[i]\n",
        "    })\n",
        "\n",
        "submission_file = \"submission.json\"\n",
        "with open(submission_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(submission_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "print(\"SUBMISSION SAVED!\")\n",
        "print(f\"File: {submission_file}\")\n",
        "print(f\"Total samples: {len(submission_data)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
